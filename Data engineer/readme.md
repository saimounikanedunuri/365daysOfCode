Summary
1. Python
2. Hadoop Ecosystem
      - Apache Spark ( Preprocessing Framework)
      - HDFS (File Storage) - little 
3. Storage System 
     - SQL (RDBMS)
4. Datawarehousing
     - Apache Hive 
5. WorkFlow Management/Orchestration - Apache Airflow 
6. Microsoft Azure
7. Overall Knowledge- Data Modeling, ETL Pipeline

**Big data concepts:**

ğŸ” What is Big Data?
- 3 V's: Volume, Velocity, Variance
- Use Cases: Netflix, Flipkart, Amazon, eBay
- Challenges: Handling and processing vast amounts of data

ğŸ’¡ Technologies to Solve Big Data Problems:
- Hadoop
- Spark
- Kafka

ğŸ“Š Hadoop Deep Dive:
Core Components:
- HDFS
- MapReduce
- YARN

ğŸ“ HDFS:
Daemons:
- NameNode
- DataNode
Architecture Overview

ğŸ”„ MapReduce:
Phases:
- Map Phase
- Reduce Phase
Process Steps

âš™ï¸ YARN:
Components:
- Resource Manager
- Node Manager

Architecture:
- Resource Scheduler
- Application Manager

ğŸ—‚ï¸ Metadata

ğŸ¯ Hive Components:
- Metastore
- Driver
- Query Compiler
- Hive Server
